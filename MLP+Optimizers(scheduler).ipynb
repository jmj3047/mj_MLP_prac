{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron(MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Library & requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "drive_project_root = \"/home/jmj3047/mj_MLP_prac\"\n",
    "sys.path.append(drive_project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch_optimizer import RAdam\n",
    "from torch_optimizer import AdamP\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "data_root = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "#preprocessing & 데이터 셋 정의\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5]) #mean, std\n",
    "    ]\n",
    ")\n",
    "\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from data_utils import dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= dataset_split(fashion_mnist_dataset, split=[0.9,0.1])\n",
    "\n",
    "train_dataset = datasets['train']\n",
    "val_dataset = datasets['val']\n",
    "\n",
    "train_batch_size = 100\n",
    "val_batch_size = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = train_batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size = val_batch_size, shuffle=True, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for sample_batch in train_dataloader:\n",
    "    print(sample_batch[0].shape, sample_batch[1].shape)\n",
    "    break\n",
    "\n",
    "#torch.Size([100, 1, 28, 28]) batchsize, channel, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델(Multi-Layer Perceptron) (MLP) 정의\n",
    "## 모델 MLPWithDropout 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch. nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=int, h1_dim = int, h2_dim = int, out_dim = int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
    "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
    "        self.relu = F.relu #activation 함수 정의\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        out = self.linear3(x)\n",
    "        out = F.sigmoid(out) #binary classification은 softmax로 사용\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MLPWithDropout(MLP):\n",
    "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n",
    "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        out = self.linear3(x)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Warmup Scheduler\n",
    "class WarmupLR(optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(self, optimpizer:optim.Optimizer, warmup_end_stops:int, last_epoch:int = -1):\n",
    "        def warmup_fn(step:int):\n",
    "            if step < warmup_end_stops:\n",
    "                return float(step)/float(max(warmup_end_stops,1))\n",
    "            return 1.0\n",
    "        \n",
    "        super().__init__(optimizer, warmup_fn, last_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선언 및 손실함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lj16zcl1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57794439db3941c48126eb891bbae3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.486 MB of 1.486 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Acc/train</td><td>▇▃▇▅▄▄▇▇▃▄▂▂█▁▆▂▂▄</td></tr><tr><td>Acc/val</td><td>█▄▁▆</td></tr><tr><td>Learning Rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/train</td><td>▃▃▆█▄▃▁▃▂▃▃▅▁▆▅▇▅▃</td></tr><tr><td>Loss/val</td><td>▁█▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Acc/train</td><td>0.09</td></tr><tr><td>Acc/val</td><td>0.09933</td></tr><tr><td>Learning Rate</td><td>0.0</td></tr><tr><td>Loss/train</td><td>0.02311</td></tr><tr><td>Loss/val</td><td>0.23134</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">2022-04-28T17:09:33-MLPWithDropout-Adam_optim_0.001_lr_with_WarmupLR_scheduler</strong>: <a href=\"https://wandb.ai/minjeejang/fastcapmus_fashion_mnist_tutorials/runs/lj16zcl1\" target=\"_blank\">https://wandb.ai/minjeejang/fastcapmus_fashion_mnist_tutorials/runs/lj16zcl1</a><br/>Synced 6 W&B file(s), 22 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220428_170933-lj16zcl1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:lj16zcl1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jmj3047/mj_MLP_prac/wandb/run-20220428_171618-3sszl7yr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/minjeejang/fastcapmus_fashion_mnist_tutorials/runs/3sszl7yr\" target=\"_blank\">2022-04-28T17:16:18-MLPWithDropout-Adam_optim_0.001_lr_with_WarmupLR_scheduler</a></strong> to <a href=\"https://wandb.ai/minjeejang/fastcapmus_fashion_mnist_tutorials\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "# model = MLP(28*28, 128, 64, 10)\n",
    "model = MLPWithDropout(28*28, 128,64,10, dropout_prob=0.3)\n",
    "model_name = type(model).__name__\n",
    "print(model_name)\n",
    "\n",
    "#define loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#define optimizer\n",
    "lr=1e-3\n",
    "# optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.AdamP(model.parameters(), lr=lr)\n",
    "optimizer_name = type(optimizer).__name__\n",
    "\n",
    "\n",
    "#define scheduler\n",
    "scheduler = WarmupLR(optimizer, 1500)\n",
    "scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "#define tensorboard logger\n",
    "run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{model_name}-{optimizer_name}_optim_{lr}_lr_with_{scheduler_name}_scheduler\"\n",
    "log_dir = f\"runs/{run_name}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# writer = SummaryWriter()\n",
    "log_interval =100\n",
    "\n",
    "#define wandb\n",
    "project_name='fastcapmus_fashion_mnist_tutorials'\n",
    "run_tags = [project_name]\n",
    "wandb.init(\n",
    "    project=project_name,\n",
    "    name=run_name,\n",
    "    tags=run_tags,\n",
    "    config={\"lr\":lr, \"model_name\":model_name, \"optimizer_name\":optimizer_name, \"scheduler_name\": scheduler_name},\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "# set save model path\n",
    "log_model_path = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(log_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "[6.666666666666667e-07]\n",
      "step 1\n",
      "[1.3333333333333334e-06]\n",
      "step 2\n",
      "[2e-06]\n",
      "step 3\n",
      "[2.666666666666667e-06]\n",
      "step 4\n",
      "[3.3333333333333337e-06]\n",
      "step 5\n",
      "[4e-06]\n",
      "step 6\n",
      "[4.666666666666667e-06]\n",
      "step 7\n",
      "[5.333333333333334e-06]\n",
      "step 8\n",
      "[6e-06]\n",
      "step 9\n",
      "[6.6666666666666675e-06]\n",
      "step 10\n",
      "[7.333333333333333e-06]\n",
      "step 11\n",
      "[8e-06]\n",
      "step 12\n",
      "[8.666666666666666e-06]\n",
      "step 13\n",
      "[9.333333333333334e-06]\n",
      "step 14\n",
      "[1e-05]\n",
      "step 15\n",
      "[1.0666666666666667e-05]\n",
      "step 16\n",
      "[1.1333333333333334e-05]\n",
      "step 17\n",
      "[1.2e-05]\n",
      "step 18\n",
      "[1.2666666666666667e-05]\n",
      "step 19\n",
      "[1.3333333333333335e-05]\n",
      "step 20\n",
      "[1.4e-05]\n",
      "step 21\n",
      "[1.4666666666666666e-05]\n",
      "step 22\n",
      "[1.5333333333333334e-05]\n",
      "step 23\n",
      "[1.6e-05]\n",
      "step 24\n",
      "[1.6666666666666667e-05]\n",
      "step 25\n",
      "[1.7333333333333332e-05]\n",
      "step 26\n",
      "[1.8e-05]\n",
      "step 27\n",
      "[1.866666666666667e-05]\n",
      "step 28\n",
      "[1.9333333333333333e-05]\n",
      "step 29\n",
      "[2e-05]\n",
      "step 30\n",
      "[2.0666666666666666e-05]\n",
      "step 31\n",
      "[2.1333333333333335e-05]\n",
      "step 32\n",
      "[2.2e-05]\n",
      "step 33\n",
      "[2.2666666666666668e-05]\n",
      "step 34\n",
      "[2.3333333333333336e-05]\n",
      "step 35\n",
      "[2.4e-05]\n",
      "step 36\n",
      "[2.466666666666667e-05]\n",
      "step 37\n",
      "[2.5333333333333334e-05]\n",
      "step 38\n",
      "[2.6e-05]\n",
      "step 39\n",
      "[2.666666666666667e-05]\n",
      "step 40\n",
      "[2.7333333333333335e-05]\n",
      "step 41\n",
      "[2.8e-05]\n",
      "step 42\n",
      "[2.8666666666666668e-05]\n",
      "step 43\n",
      "[2.9333333333333333e-05]\n",
      "step 44\n",
      "[3e-05]\n",
      "step 45\n",
      "[3.066666666666667e-05]\n",
      "step 46\n",
      "[3.1333333333333334e-05]\n",
      "step 47\n",
      "[3.2e-05]\n",
      "step 48\n",
      "[3.266666666666666e-05]\n",
      "step 49\n",
      "[3.3333333333333335e-05]\n",
      "step 50\n",
      "[3.4000000000000007e-05]\n",
      "step 51\n",
      "[3.4666666666666665e-05]\n",
      "step 52\n",
      "[3.5333333333333336e-05]\n",
      "step 53\n",
      "[3.6e-05]\n",
      "step 54\n",
      "[3.6666666666666666e-05]\n",
      "step 55\n",
      "[3.733333333333334e-05]\n",
      "step 56\n",
      "[3.8e-05]\n",
      "step 57\n",
      "[3.866666666666667e-05]\n",
      "step 58\n",
      "[3.933333333333333e-05]\n",
      "step 59\n",
      "[4e-05]\n",
      "step 60\n",
      "[4.066666666666666e-05]\n",
      "step 61\n",
      "[4.133333333333333e-05]\n",
      "step 62\n",
      "[4.2000000000000004e-05]\n",
      "step 63\n",
      "[4.266666666666667e-05]\n",
      "step 64\n",
      "[4.3333333333333334e-05]\n",
      "step 65\n",
      "[4.4e-05]\n",
      "step 66\n",
      "[4.466666666666667e-05]\n",
      "step 67\n",
      "[4.5333333333333335e-05]\n",
      "step 68\n",
      "[4.6e-05]\n",
      "step 69\n",
      "[4.666666666666667e-05]\n",
      "step 70\n",
      "[4.733333333333333e-05]\n",
      "step 71\n",
      "[4.8e-05]\n",
      "step 72\n",
      "[4.8666666666666666e-05]\n",
      "step 73\n",
      "[4.933333333333334e-05]\n",
      "step 74\n",
      "[5e-05]\n",
      "step 75\n",
      "[5.066666666666667e-05]\n",
      "step 76\n",
      "[5.133333333333334e-05]\n",
      "step 77\n",
      "[5.2e-05]\n",
      "step 78\n",
      "[5.266666666666667e-05]\n",
      "step 79\n",
      "[5.333333333333334e-05]\n",
      "step 80\n",
      "[5.4e-05]\n",
      "step 81\n",
      "[5.466666666666667e-05]\n",
      "step 82\n",
      "[5.5333333333333334e-05]\n",
      "step 83\n",
      "[5.6e-05]\n",
      "step 84\n",
      "[5.6666666666666664e-05]\n",
      "step 85\n",
      "[5.7333333333333336e-05]\n",
      "step 86\n",
      "[5.800000000000001e-05]\n",
      "step 87\n",
      "[5.8666666666666665e-05]\n",
      "step 88\n",
      "[5.933333333333334e-05]\n",
      "step 89\n",
      "[6e-05]\n",
      "step 90\n",
      "[6.0666666666666666e-05]\n",
      "step 91\n",
      "[6.133333333333334e-05]\n",
      "step 92\n",
      "[6.2e-05]\n",
      "step 93\n",
      "[6.266666666666667e-05]\n",
      "step 94\n",
      "[6.333333333333335e-05]\n",
      "step 95\n",
      "[6.4e-05]\n",
      "step 96\n",
      "[6.466666666666666e-05]\n",
      "step 97\n",
      "[6.533333333333333e-05]\n",
      "step 98\n",
      "[6.6e-05]\n",
      "step 99\n",
      "[6.666666666666667e-05]\n",
      "step 100\n",
      "[6.733333333333333e-05]\n",
      "step 101\n",
      "[6.800000000000001e-05]\n",
      "step 102\n",
      "[6.866666666666666e-05]\n",
      "step 103\n",
      "[6.933333333333333e-05]\n",
      "step 104\n",
      "[7.000000000000001e-05]\n",
      "step 105\n",
      "[7.066666666666667e-05]\n",
      "step 106\n",
      "[7.133333333333334e-05]\n",
      "step 107\n",
      "[7.2e-05]\n",
      "step 108\n",
      "[7.266666666666667e-05]\n",
      "step 109\n",
      "[7.333333333333333e-05]\n",
      "step 110\n",
      "[7.4e-05]\n",
      "step 111\n",
      "[7.466666666666667e-05]\n",
      "step 112\n",
      "[7.533333333333334e-05]\n",
      "step 113\n",
      "[7.6e-05]\n",
      "step 114\n",
      "[7.666666666666667e-05]\n",
      "step 115\n",
      "[7.733333333333333e-05]\n",
      "step 116\n",
      "[7.8e-05]\n",
      "step 117\n",
      "[7.866666666666666e-05]\n",
      "step 118\n",
      "[7.933333333333334e-05]\n",
      "step 119\n",
      "[8e-05]\n",
      "step 120\n",
      "[8.066666666666667e-05]\n",
      "step 121\n",
      "[8.133333333333332e-05]\n",
      "step 122\n",
      "[8.2e-05]\n",
      "step 123\n",
      "[8.266666666666667e-05]\n",
      "step 124\n",
      "[8.333333333333333e-05]\n",
      "step 125\n",
      "[8.400000000000001e-05]\n",
      "step 126\n",
      "[8.466666666666667e-05]\n",
      "step 127\n",
      "[8.533333333333334e-05]\n",
      "step 128\n",
      "[8.599999999999999e-05]\n",
      "step 129\n",
      "[8.666666666666667e-05]\n",
      "step 130\n",
      "[8.733333333333333e-05]\n",
      "step 131\n",
      "[8.8e-05]\n",
      "step 132\n",
      "[8.866666666666668e-05]\n",
      "step 133\n",
      "[8.933333333333334e-05]\n",
      "step 134\n",
      "[8.999999999999999e-05]\n",
      "step 135\n",
      "[9.066666666666667e-05]\n",
      "step 136\n",
      "[9.133333333333334e-05]\n",
      "step 137\n",
      "[9.2e-05]\n",
      "step 138\n",
      "[9.266666666666666e-05]\n",
      "step 139\n",
      "[9.333333333333334e-05]\n",
      "step 140\n",
      "[9.400000000000001e-05]\n",
      "step 141\n",
      "[9.466666666666666e-05]\n",
      "step 142\n",
      "[9.533333333333334e-05]\n",
      "step 143\n",
      "[9.6e-05]\n",
      "step 144\n",
      "[9.666666666666667e-05]\n",
      "step 145\n",
      "[9.733333333333333e-05]\n",
      "step 146\n",
      "[9.800000000000001e-05]\n",
      "step 147\n",
      "[9.866666666666668e-05]\n",
      "step 148\n",
      "[9.933333333333333e-05]\n",
      "step 149\n",
      "[0.0001]\n",
      "step 150\n",
      "[0.00010066666666666667]\n",
      "step 151\n",
      "[0.00010133333333333333]\n",
      "step 152\n",
      "[0.000102]\n",
      "step 153\n",
      "[0.00010266666666666668]\n",
      "step 154\n",
      "[0.00010333333333333333]\n",
      "step 155\n",
      "[0.000104]\n",
      "step 156\n",
      "[0.00010466666666666667]\n",
      "step 157\n",
      "[0.00010533333333333334]\n",
      "step 158\n",
      "[0.000106]\n",
      "step 159\n",
      "[0.00010666666666666668]\n",
      "step 160\n",
      "[0.00010733333333333334]\n",
      "step 161\n",
      "[0.000108]\n",
      "step 162\n",
      "[0.00010866666666666666]\n",
      "step 163\n",
      "[0.00010933333333333334]\n",
      "step 164\n",
      "[0.00011]\n",
      "step 165\n",
      "[0.00011066666666666667]\n",
      "step 166\n",
      "[0.00011133333333333335]\n",
      "step 167\n",
      "[0.000112]\n",
      "step 168\n",
      "[0.00011266666666666666]\n",
      "step 169\n",
      "[0.00011333333333333333]\n",
      "step 170\n",
      "[0.000114]\n",
      "step 171\n",
      "[0.00011466666666666667]\n",
      "step 172\n",
      "[0.00011533333333333334]\n",
      "step 173\n",
      "[0.00011600000000000001]\n",
      "step 174\n",
      "[0.00011666666666666667]\n",
      "step 175\n",
      "[0.00011733333333333333]\n",
      "step 176\n",
      "[0.000118]\n",
      "step 177\n",
      "[0.00011866666666666667]\n",
      "step 178\n",
      "[0.00011933333333333334]\n",
      "step 179\n",
      "[0.00012]\n",
      "step 180\n",
      "[0.00012066666666666667]\n",
      "step 181\n",
      "[0.00012133333333333333]\n",
      "step 182\n",
      "[0.000122]\n",
      "step 183\n",
      "[0.00012266666666666668]\n",
      "step 184\n",
      "[0.00012333333333333334]\n",
      "step 185\n",
      "[0.000124]\n",
      "step 186\n",
      "[0.00012466666666666667]\n",
      "step 187\n",
      "[0.00012533333333333334]\n",
      "step 188\n",
      "[0.000126]\n",
      "step 189\n",
      "[0.0001266666666666667]\n",
      "step 190\n",
      "[0.00012733333333333333]\n",
      "step 191\n",
      "[0.000128]\n",
      "step 192\n",
      "[0.00012866666666666669]\n",
      "step 193\n",
      "[0.00012933333333333332]\n",
      "step 194\n",
      "[0.00013000000000000002]\n",
      "step 195\n",
      "[0.00013066666666666665]\n",
      "step 196\n",
      "[0.00013133333333333335]\n",
      "step 197\n",
      "[0.000132]\n",
      "step 198\n",
      "[0.00013266666666666665]\n",
      "step 199\n",
      "[0.00013333333333333334]\n",
      "step 200\n",
      "[0.000134]\n",
      "step 201\n",
      "[0.00013466666666666667]\n",
      "step 202\n",
      "[0.00013533333333333333]\n",
      "step 203\n",
      "[0.00013600000000000003]\n",
      "step 204\n",
      "[0.00013666666666666666]\n",
      "step 205\n",
      "[0.00013733333333333333]\n",
      "step 206\n",
      "[0.00013800000000000002]\n",
      "step 207\n",
      "[0.00013866666666666666]\n",
      "step 208\n",
      "[0.00013933333333333335]\n",
      "step 209\n",
      "[0.00014000000000000001]\n",
      "step 210\n",
      "[0.00014066666666666665]\n",
      "step 211\n",
      "[0.00014133333333333334]\n",
      "step 212\n",
      "[0.00014199999999999998]\n",
      "step 213\n",
      "[0.00014266666666666667]\n",
      "step 214\n",
      "[0.00014333333333333334]\n",
      "step 215\n",
      "[0.000144]\n",
      "step 216\n",
      "[0.00014466666666666667]\n",
      "step 217\n",
      "[0.00014533333333333333]\n",
      "step 218\n",
      "[0.000146]\n",
      "step 219\n",
      "[0.00014666666666666666]\n",
      "step 220\n",
      "[0.00014733333333333335]\n",
      "step 221\n",
      "[0.000148]\n",
      "step 222\n",
      "[0.00014866666666666668]\n",
      "step 223\n",
      "[0.00014933333333333335]\n",
      "step 224\n",
      "[0.00015]\n",
      "step 225\n",
      "[0.00015066666666666668]\n",
      "step 226\n",
      "[0.00015133333333333332]\n",
      "step 227\n",
      "[0.000152]\n",
      "step 228\n",
      "[0.00015266666666666667]\n",
      "step 229\n",
      "[0.00015333333333333334]\n",
      "step 230\n",
      "[0.000154]\n",
      "step 231\n",
      "[0.00015466666666666667]\n",
      "step 232\n",
      "[0.00015533333333333333]\n",
      "step 233\n",
      "[0.000156]\n",
      "step 234\n",
      "[0.0001566666666666667]\n",
      "step 235\n",
      "[0.00015733333333333333]\n",
      "step 236\n",
      "[0.000158]\n",
      "step 237\n",
      "[0.00015866666666666668]\n",
      "step 238\n",
      "[0.00015933333333333332]\n",
      "step 239\n",
      "[0.00016]\n",
      "step 240\n",
      "[0.00016066666666666668]\n",
      "step 241\n",
      "[0.00016133333333333334]\n",
      "step 242\n",
      "[0.000162]\n",
      "step 243\n",
      "[0.00016266666666666665]\n",
      "step 244\n",
      "[0.00016333333333333334]\n",
      "step 245\n",
      "[0.000164]\n",
      "step 246\n",
      "[0.00016466666666666667]\n",
      "step 247\n",
      "[0.00016533333333333333]\n",
      "step 248\n",
      "[0.00016600000000000002]\n",
      "step 249\n",
      "[0.00016666666666666666]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(250):\n",
    "#     print(\"step\",i)\n",
    "#     optimizer.step()\n",
    "#     scheduler.step()\n",
    "#     print(scheduler.get_last_lr())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping callback Object Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.ckpt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None: #loss가 최소화 됐을때 save_checkpoint를 저장함\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta: #모델 성능이 더이상 개선되지 않는다 했을 때 early stopping이 됨\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: #개선이 안됐다고 바로 하는게 아니라 조금 기다렸다가 stop함\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        \n",
    "        filename = self.path.split('/')[-1]\n",
    "        save_dir = os.path.dirname(self.path)\n",
    "        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\")) #어떤 score에서 멈췄는지가 중요하기 때문에 그걸 print해줌\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 31906), started 6:00:31 ago. (Use '!kill 31906' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f0062658295ad73b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f0062658295ad73b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 600/600 [00:03<00:00, 182.23it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch, 0 step: val_loss: 0.23030848801136017, val_acc: 0.11349983513355255\n",
      "Validation loss decreased (inf --> 0.230308).  Saving model ...\n",
      "0: train_loss: 0.02321147680282593, train_acc: 0.05999999865889549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▉        | 103/540 [00:03<00:17, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: train_loss: 0.019636197090148924, train_acc: 0.4399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  37%|███▋      | 198/540 [00:05<00:08, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: train_loss: 0.009831223487854004, train_acc: 0.6600000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 301/540 [00:09<00:08, 29.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300: train_loss: 0.006794642806053162, train_acc: 0.7099999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  74%|███████▍  | 402/540 [00:12<00:04, 31.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: train_loss: 0.006486737132072449, train_acc: 0.7799999713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  92%|█████████▏| 498/540 [00:15<00:01, 39.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: train_loss: 0.005031418800354004, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 32.53it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 192.48it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch, 540 step: val_loss: 0.050071582198143005, val_acc: 0.812665581703186\n",
      "Validation loss decreased (0.230308 --> 0.050072).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|█         | 60/540 [00:01<00:11, 41.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: train_loss: 0.002996535003185272, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|██▉       | 161/540 [00:04<00:12, 30.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700: train_loss: 0.004140161275863648, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  48%|████▊     | 261/540 [00:08<00:11, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: train_loss: 0.005097847580909729, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 361/540 [00:10<00:06, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: train_loss: 0.004480385184288025, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  85%|████████▌ | 460/540 [00:13<00:02, 38.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: train_loss: 0.005725134611129761, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 34.16it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 191.22it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch, 1080 step: val_loss: 0.0404016450047493, val_acc: 0.8483310341835022\n",
      "Validation loss decreased (0.050072 --> 0.040402).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▍         | 21/540 [00:00<00:20, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100: train_loss: 0.0038103798031806947, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  22%|██▏       | 121/540 [00:03<00:13, 32.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200: train_loss: 0.006873905062675476, train_acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████▏     | 224/540 [00:06<00:10, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300: train_loss: 0.0036726269125938417, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  59%|█████▉    | 318/540 [00:09<00:05, 40.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400: train_loss: 0.0031255576014518737, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 419/540 [00:12<00:03, 40.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500: train_loss: 0.004365328550338745, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  97%|█████████▋| 522/540 [00:16<00:00, 33.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600: train_loss: 0.00358129620552063, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 32.70it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 184.36it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch, 1620 step: val_loss: 0.03875868022441864, val_acc: 0.8563312888145447\n",
      "Validation loss decreased (0.040402 --> 0.038759).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  15%|█▌        | 83/540 [00:02<00:26, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700: train_loss: 0.004677234888076782, train_acc: 0.7799999713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▍      | 183/540 [00:05<00:11, 31.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800: train_loss: 0.0029335442185401918, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 282/540 [00:08<00:08, 31.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900: train_loss: 0.004306874871253967, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 384/540 [00:11<00:04, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: train_loss: 0.0027357444167137148, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████▉ | 483/540 [00:14<00:02, 22.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100: train_loss: 0.003340786397457123, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 33.03it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 188.92it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch, 2160 step: val_loss: 0.03694036975502968, val_acc: 0.8644976615905762\n",
      "Validation loss decreased (0.038759 --> 0.036940).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   8%|▊         | 41/540 [00:01<00:16, 29.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200: train_loss: 0.001803548187017441, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  26%|██▋       | 143/540 [00:04<00:11, 34.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300: train_loss: 0.003264753222465515, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  45%|████▌     | 243/540 [00:07<00:10, 29.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400: train_loss: 0.003702031970024109, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|██████▎   | 341/540 [00:09<00:07, 27.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500: train_loss: 0.0024851682782173158, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  81%|████████▏ | 439/540 [00:12<00:02, 43.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600: train_loss: 0.0027844998240470886, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 33.98it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 229.12it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch, 2700 step: val_loss: 0.034165266901254654, val_acc: 0.8734978437423706\n",
      "Validation loss decreased (0.036940 --> 0.034165).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 1/540 [00:00<07:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700: train_loss: 0.002941945195198059, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▊        | 100/540 [00:03<00:10, 41.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800: train_loss: 0.002809327244758606, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  37%|███▋      | 200/540 [00:06<00:07, 43.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900: train_loss: 0.0036588704586029055, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 302/540 [00:09<00:08, 28.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: train_loss: 0.003284720480442047, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  75%|███████▍  | 403/540 [00:12<00:07, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100: train_loss: 0.002105095237493515, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 504/540 [00:15<00:01, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: train_loss: 0.0019780132174491882, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 31.86it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 233.09it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch, 3240 step: val_loss: 0.0348842591047287, val_acc: 0.8703314065933228\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|█         | 58/540 [00:02<00:12, 39.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300: train_loss: 0.0036505481600761416, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 162/540 [00:05<00:15, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400: train_loss: 0.0032103881239891052, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  48%|████▊     | 260/540 [00:07<00:06, 41.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500: train_loss: 0.002902999222278595, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 360/540 [00:10<00:04, 38.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600: train_loss: 0.0024064603447914125, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 462/540 [00:14<00:03, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700: train_loss: 0.0020909181237220766, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 33.92it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 184.89it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch, 3780 step: val_loss: 0.03267619386315346, val_acc: 0.878331184387207\n",
      "Validation loss decreased (0.034165 --> 0.032676).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▎         | 20/540 [00:00<00:13, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800: train_loss: 0.002644225060939789, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  22%|██▏       | 121/540 [00:04<00:14, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900: train_loss: 0.002769676446914673, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████▏     | 223/540 [00:06<00:10, 28.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000: train_loss: 0.0026638203859329222, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  59%|█████▉    | 320/540 [00:09<00:05, 42.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100: train_loss: 0.0031588879227638245, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 421/540 [00:13<00:03, 31.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200: train_loss: 0.0024489633738994598, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  96%|█████████▋| 521/540 [00:16<00:00, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300: train_loss: 0.004779299795627594, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 32.60it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 184.97it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch, 4320 step: val_loss: 0.03404197841882706, val_acc: 0.8788312673568726\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  15%|█▌        | 82/540 [00:02<00:14, 32.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400: train_loss: 0.002437058985233307, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▍      | 185/540 [00:05<00:10, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500: train_loss: 0.002175253629684448, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 281/540 [00:08<00:09, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600: train_loss: 0.004665202796459198, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 382/540 [00:11<00:04, 32.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700: train_loss: 0.0020062702894210814, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  90%|████████▉ | 484/540 [00:14<00:01, 34.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800: train_loss: 0.003386185169219971, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 34.87it/s]\n",
      "validation: 100%|██████████| 600/600 [00:03<00:00, 185.24it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epoch, 4860 step: val_loss: 0.030544213950634003, val_acc: 0.8879980444908142\n",
      "Validation loss decreased (0.032676 --> 0.030544).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   7%|▋         | 37/540 [00:01<00:12, 39.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900: train_loss: 0.0026332315802574157, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  26%|██▋       | 142/540 [00:04<00:13, 28.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000: train_loss: 0.001243176832795143, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  45%|████▍     | 242/540 [00:07<00:12, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100: train_loss: 0.0031729137897491457, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|██████▎   | 342/540 [00:10<00:06, 31.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200: train_loss: 0.0013619294762611388, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  82%|████████▏ | 442/540 [00:13<00:03, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300: train_loss: 0.0019896873831748963, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:16<00:00, 32.13it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/ #여기다가 log를 쌓을거고 거기 있는걸 plot해달라는 의미\n",
    "\n",
    "#define EarlyStopping\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=3, verbose=True, path = os.path.join(log_model_path, \"model.ckpt\")\n",
    ")\n",
    "\n",
    "#do train with validation\n",
    "train_step = 0\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    #validation step\n",
    "    with torch.no_grad(): # optimizer가 업데이트 하면 안됨\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        model.eval()\n",
    "\n",
    "        for val_batch_idx, (val_images, val_labels) in enumerate(\n",
    "            tqdm(val_dataloader, position=0, leave=True, desc = 'validation')\n",
    "        ):\n",
    "            #forward\n",
    "            val_outputs = model(val_images)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            \n",
    "            #loss & acc\n",
    "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0] #이게 batch size. batch size만큼 평균을 내겠다는 뜻\n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
    "        \n",
    "        #valid step logging\n",
    "        val_epoch_loss = val_loss / len(val_dataloader)\n",
    "        val_epoch_acc = val_corrects/len(val_dataloader)\n",
    "        print(\n",
    "            f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\" \n",
    "        )\n",
    "\n",
    "        #tensorboard log\n",
    "        writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n",
    "        writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n",
    "        writer.add_images(\"Images/val\", val_images, train_step)\n",
    "\n",
    "        #wandb log\n",
    "        wandb.log({\n",
    "            \"Loss/val\":val_epoch_loss,\n",
    "            \"Acc/val\": val_epoch_acc,\n",
    "            \"Images/val\": wandb.Image(val_images),\n",
    "            \"Outputs/val\": wandb.Histogram(val_outputs.detach().numpy()),\n",
    "            \"Preds/val\": wandb.Histogram(val_preds.detach().numpy()),\n",
    "            \"Labels/val\": wandb.Histogram(val_labels.data.detach().numpy()),\n",
    "        }, step=train_step)\n",
    "\n",
    "        # check early stopping point & save model if model reached the best performance\n",
    "        early_stopper(val_epoch_loss, model)\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "        \n",
    "        #train step\n",
    "        current_loss = 0\n",
    "        current_corrects = 0\n",
    "        model\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    #train step\n",
    "    for batch_idx, (images, labels) in enumerate(\n",
    "         tqdm(train_dataloader, position=0, leave=True, desc = 'train')\n",
    "    ):\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        #get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # print(outputs)\n",
    "        # print(preds)\n",
    "        \n",
    "        #get loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "\n",
    "        ###### 여기까지가 forward ###\n",
    "\n",
    "        #Backpropagation\n",
    "\n",
    "        #optimitizer 초기화(zero화)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #perfrom optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        #Perform LR Scheduler work\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        current_loss +=loss.item()\n",
    "        current_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if train_step % log_interval == 0:\n",
    "            train_loss = current_loss / log_interval\n",
    "            train_acc = current_corrects/log_interval\n",
    "            print(\n",
    "                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\" \n",
    "            )\n",
    "\n",
    "            #tensorboard log\n",
    "            writer.add_scalar(\"Loss/train\", train_step)\n",
    "            writer.add_scalar(\"Acc/train\", train_step)\n",
    "            writer.add_images(\"Images/train\", images, train_step)\n",
    "            writer.add_scalar(\"Learning Rate\", scheduler.get_last_lr()[0],train_step)\n",
    "            writer.add_graph(model, images)\n",
    "            \n",
    "            \n",
    "            # wandb log\n",
    "            wandb.log({\n",
    "                \"Loss/train\": train_loss,\n",
    "                \"Acc/train\": train_acc,\n",
    "                \"Images/train\": wandb.Image(images),\n",
    "                \"Outputs/train\": wandb.Histogram(outputs.detach().cpu().numpy()),\n",
    "                \"Preds/train\": wandb.Histogram(preds.detach().cpu().numpy()),\n",
    "                \"Labels/train\": wandb.Histogram(labels.data.detach().cpu().numpy()),\n",
    "                \"Learning Rate\": scheduler.get_last_lr()[0], \n",
    "            }, step=train_step)\n",
    "\n",
    "            current_loss = 0\n",
    "            current_corrects = 0\n",
    "\n",
    "        train_step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# os.makedirs(\"./logs/models\", exist_ok=True)\n",
    "# torch.save(model, os.path.join(log_model_path, \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "# loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.03366972133517265-model.ckpt\"))\n",
    "loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.0404016450047493-model.ckpt\"))\n",
    "\n",
    "loaded_model.eval()\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"numpy softmax\"\n",
    "    max = np.max(x, axis=axis, keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x, axis = axis, keepdims=True)\n",
    "    f_x = e_x / sum\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 100/100 [00:01<00:00, 68.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n",
    "    #forward\n",
    "    test_outputs = loaded_model(test_images)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.detach().numpy())\n",
    "    test_labels_list.extend(test_preds.detach().numpy())\n",
    "\n",
    "test_preds_list = np.array(test_preds_list)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "print(f\"acc: {np.mean(test_preds_list==test_labels_list)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912813082413846\n"
     ]
    }
   ],
   "source": [
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr={}\n",
    "tpr={}\n",
    "thresh={}\n",
    "n_class = 10\n",
    "\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:,i], pos_label=i)\n",
    "\n",
    "#print(fpr)\n",
    "\n",
    "#plot\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], linestyle = '--', label=f\"class{i} vs Rest\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(test_labels_list, test_outputs_list, multi_class='ovo', average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7244abc13d988a7e7d2c4c53272249ae82a63923609912adda01122398923101"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
