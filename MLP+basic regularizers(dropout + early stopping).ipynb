{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron(MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Library & requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "drive_project_root = \"/home/jmj3047/mj_MLP_prac\"\n",
    "sys.path.append(drive_project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "data_root = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "#preprocessing & 데이터 셋 정의\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5],[0.5]) #mean, std\n",
    "    ]\n",
    ")\n",
    "\n",
    "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from data_utils import dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= dataset_split(fashion_mnist_dataset, split=[0.9,0.1])\n",
    "\n",
    "train_dataset = datasets['train']\n",
    "val_dataset = datasets['val']\n",
    "\n",
    "train_batch_size = 100\n",
    "val_batch_size = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = train_batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size = val_batch_size, shuffle=True, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for sample_batch in train_dataloader:\n",
    "    print(sample_batch[0].shape, sample_batch[1].shape)\n",
    "    break\n",
    "\n",
    "#torch.Size([100, 1, 28, 28]) batchsize, channel, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델(Multi-Layer Perceptron) (MLP) 정의\n",
    "## 모델 MLPWithDropout 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch. nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=int, h1_dim = int, h2_dim = int, out_dim = int):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
    "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
    "        self.relu = F.relu #activation 함수 정의\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        out = self.linear3(x)\n",
    "        out = F.sigmoid(out) #binary classification은 softmax로 사용\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MLPWithDropout(MLP):\n",
    "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n",
    "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = torch.flatten(input, start_dim=1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        out = self.linear3(x)\n",
    "        # out = F.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선언 및 손실함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "# model = MLP(28*28, 128, 64, 10)\n",
    "model = MLPWithDropout(28*28, 128,64,10, dropout_prob=0.3)\n",
    "model_name = type(model).__name__\n",
    "print(model_name)\n",
    "\n",
    "#define loss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "#define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n",
    "max_epoch = 10\n",
    "\n",
    "#define tensorboard logger\n",
    "log_dir = f\"runs/{datetime.now()}-{model_name}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# writer = SummaryWriter()\n",
    "log_interval =100\n",
    "\n",
    "# set save model path\n",
    "log_model_path = os.path.join(log_dir, \"models\")\n",
    "os.makedirs(log_model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping callback Object Class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With some modifications, source is from https://github.com/Bjarten/early-stopping-pytorch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.ckpt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.ckpt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None: #loss가 최소화 됐을때 save_checkpoint를 저장함\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta: #모델 성능이 더이상 개선되지 않는다 했을 때 early stopping이 됨\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: #개선이 안됐다고 바로 하는게 아니라 조금 기다렸다가 stop함\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        \n",
    "        filename = self.path.split('/')[-1]\n",
    "        save_dir = os.path.dirname(self.path)\n",
    "        torch.save(model, os.path.join(save_dir, f\"val_loss-{val_loss}-{filename}\")) #어떤 score에서 멈췄는지가 중요하기 때문에 그걸 print해줌\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 31906), started 4:15:33 ago. (Use '!kill 31906' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-47866732783c1bb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-47866732783c1bb\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 600/600 [00:02<00:00, 240.28it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch, 0 step: val_loss: 0.23035308718681335, val_acc: 0.09666651487350464\n",
      "Validation loss decreased (inf --> 0.230353).  Saving model ...\n",
      "0: train_loss: 0.023103275299072266, train_acc: 0.10000000149011612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▊        | 101/540 [00:02<00:13, 31.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: train_loss: 0.006068005561828614, train_acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  38%|███▊      | 205/540 [00:05<00:09, 34.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200: train_loss: 0.005702927112579346, train_acc: 0.7599999904632568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 301/540 [00:08<00:08, 29.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300: train_loss: 0.005056851506233215, train_acc: 0.8199999928474426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  75%|███████▌  | 405/540 [00:10<00:03, 38.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: train_loss: 0.004364617168903351, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 501/540 [00:13<00:01, 31.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: train_loss: 0.0035428255796432495, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 35.83it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 240.20it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epoch, 540 step: val_loss: 0.04364863038063049, val_acc: 0.8376650214195251\n",
      "Validation loss decreased (0.230353 --> 0.043649).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  12%|█▏        | 65/540 [00:01<00:14, 33.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600: train_loss: 0.002477666437625885, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 163/540 [00:04<00:24, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700: train_loss: 0.003697135150432587, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  48%|████▊     | 261/540 [00:07<00:08, 31.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: train_loss: 0.0038509243726730347, train_acc: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  68%|██████▊   | 365/540 [00:10<00:04, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: train_loss: 0.0035421961545944215, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 465/540 [00:13<00:04, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: train_loss: 0.003900415301322937, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:14<00:00, 36.38it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 234.60it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epoch, 1080 step: val_loss: 0.037912704050540924, val_acc: 0.8609982132911682\n",
      "Validation loss decreased (0.043649 --> 0.037913).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▍         | 21/540 [00:00<00:18, 27.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100: train_loss: 0.005417489409446716, train_acc: 0.8100000023841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  21%|██▏       | 116/540 [00:03<00:11, 37.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200: train_loss: 0.005331524014472962, train_acc: 0.7699999809265137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████      | 221/540 [00:06<00:09, 34.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300: train_loss: 0.0028566533327102663, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  60%|█████▉    | 323/540 [00:08<00:06, 34.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400: train_loss: 0.0031241199374198916, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 423/540 [00:11<00:03, 33.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500: train_loss: 0.0028911587595939637, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  96%|█████████▋| 521/540 [00:14<00:00, 31.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600: train_loss: 0.0030061662197113036, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:14<00:00, 36.06it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 248.43it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 epoch, 1620 step: val_loss: 0.03575781360268593, val_acc: 0.8681640625\n",
      "Validation loss decreased (0.037913 --> 0.035758).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  16%|█▌        | 84/540 [00:02<00:13, 32.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700: train_loss: 0.0021404443681240083, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▍      | 185/540 [00:05<00:09, 36.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800: train_loss: 0.002276214361190796, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 281/540 [00:07<00:09, 28.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900: train_loss: 0.004952814877033234, train_acc: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 382/540 [00:10<00:05, 30.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: train_loss: 0.003769998252391815, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████▉ | 482/540 [00:13<00:01, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100: train_loss: 0.0039564380049705505, train_acc: 0.8299999833106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:14<00:00, 36.05it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 260.69it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epoch, 2160 step: val_loss: 0.03462181240320206, val_acc: 0.8739975094795227\n",
      "Validation loss decreased (0.035758 --> 0.034622).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   8%|▊         | 41/540 [00:01<00:16, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200: train_loss: 0.003867652416229248, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  27%|██▋       | 144/540 [00:04<00:11, 33.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300: train_loss: 0.0024657072126865387, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  46%|████▌     | 246/540 [00:06<00:07, 36.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400: train_loss: 0.004069816470146179, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|██████▎   | 341/540 [00:09<00:05, 33.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500: train_loss: 0.0032155823707580564, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  82%|████████▏ | 445/540 [00:12<00:02, 33.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600: train_loss: 0.0023466287553310394, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:14<00:00, 36.60it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 244.83it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 epoch, 2700 step: val_loss: 0.0352231003344059, val_acc: 0.8703309893608093\n",
      "EarlyStopping counter: 1 out of 3\n",
      "2700: train_loss: 0.0030283153057098387, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  19%|█▉        | 102/540 [00:03<00:30, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800: train_loss: 0.002282608151435852, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  38%|███▊      | 205/540 [00:06<00:09, 33.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900: train_loss: 0.0016799382865428925, train_acc: 0.9399999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████▌    | 303/540 [00:08<00:07, 33.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000: train_loss: 0.003069417178630829, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  74%|███████▍  | 401/540 [00:11<00:04, 33.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100: train_loss: 0.0012197183817625045, train_acc: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  93%|█████████▎| 504/540 [00:14<00:01, 31.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: train_loss: 0.0023747621476650238, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 35.64it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 248.09it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 epoch, 3240 step: val_loss: 0.03366972133517265, val_acc: 0.8774977326393127\n",
      "Validation loss decreased (0.034622 --> 0.033670).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  12%|█▏        | 65/540 [00:01<00:13, 34.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300: train_loss: 0.002598412334918976, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███       | 163/540 [00:04<00:24, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400: train_loss: 0.003988162279129028, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  49%|████▊     | 263/540 [00:07<00:08, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500: train_loss: 0.0036907505989074705, train_acc: 0.8399999737739563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|██████▋   | 364/540 [00:10<00:05, 34.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600: train_loss: 0.0031452548503875734, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 462/540 [00:12<00:02, 33.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700: train_loss: 0.0035971441864967348, train_acc: 0.8600000143051147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 35.43it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 232.56it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 epoch, 3780 step: val_loss: 0.0364859402179718, val_acc: 0.8671644926071167\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   4%|▍         | 21/540 [00:00<00:18, 28.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800: train_loss: 0.0028773733973503114, train_acc: 0.8700000047683716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  23%|██▎       | 122/540 [00:03<00:12, 33.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900: train_loss: 0.0030748343467712404, train_acc: 0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  41%|████      | 222/540 [00:06<00:10, 31.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000: train_loss: 0.001909531056880951, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  60%|██████    | 325/540 [00:08<00:06, 33.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100: train_loss: 0.0016524963080883025, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  78%|███████▊  | 421/540 [00:11<00:03, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200: train_loss: 0.003104139268398285, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  96%|█████████▋| 521/540 [00:14<00:00, 32.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300: train_loss: 0.0026103359460830687, train_acc: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:14<00:00, 36.38it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 246.52it/s]\n",
      "train:   0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 epoch, 4320 step: val_loss: 0.035119447857141495, val_acc: 0.8749983906745911\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  16%|█▌        | 85/540 [00:02<00:13, 34.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400: train_loss: 0.002218441069126129, train_acc: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|███▍      | 184/540 [00:05<00:10, 35.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500: train_loss: 0.0022922100126743315, train_acc: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  52%|█████▏    | 283/540 [00:07<00:08, 31.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600: train_loss: 0.003106357753276825, train_acc: 0.8799999952316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  71%|███████   | 383/540 [00:10<00:04, 32.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700: train_loss: 0.0022266386449337006, train_acc: 0.9100000262260437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████▉ | 481/540 [00:13<00:02, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800: train_loss: 0.002425556629896164, train_acc: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 540/540 [00:15<00:00, 35.94it/s]\n",
      "validation: 100%|██████████| 600/600 [00:02<00:00, 266.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 epoch, 4860 step: val_loss: 0.03368304297327995, val_acc: 0.8746644854545593\n",
      "EarlyStopping counter: 3 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/ #여기다가 log를 쌓을거고 거기 있는걸 plot해달라는 의미\n",
    "\n",
    "#define EarlyStopping\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=3, verbose=True, path = os.path.join(log_model_path, \"model.ckpt\")\n",
    ")\n",
    "\n",
    "#do train with validation\n",
    "train_step = 0\n",
    "for epoch in range(1, max_epoch+1):\n",
    "    #validation step\n",
    "    with torch.no_grad(): # optimizer가 업데이트 하면 안됨\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        model.eval()\n",
    "\n",
    "        for val_batch_idx, (val_images, val_labels) in enumerate(\n",
    "            tqdm(val_dataloader, position=0, leave=True, desc = 'validation')\n",
    "        ):\n",
    "            #forward\n",
    "            val_outputs = model(val_images)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            \n",
    "            #loss & acc\n",
    "            val_loss += loss_function(val_outputs, val_labels) / val_outputs.shape[0] #이게 batch size. batch size만큼 평균을 내겠다는 뜻\n",
    "            val_corrects += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
    "        \n",
    "        #valid step logging\n",
    "        val_epoch_loss = val_loss / len(val_dataloader)\n",
    "        val_epoch_acc = val_corrects/len(val_dataloader)\n",
    "        print(\n",
    "            f\"{epoch} epoch, {train_step} step: val_loss: {val_epoch_loss}, val_acc: {val_epoch_acc}\" \n",
    "        )\n",
    "        writer.add_scalar(\"Loss/val\", val_epoch_loss, train_step)\n",
    "        writer.add_scalar(\"Acc/val\", val_epoch_acc, train_step)\n",
    "        writer.add_images(\"Images/val\", val_images, train_step)\n",
    "\n",
    "        # check early stopping point & save model if model reached the best performance\n",
    "        early_stopper(val_epoch_loss, model)\n",
    "        if early_stopper.early_stop:\n",
    "            break\n",
    "        \n",
    "        #train step\n",
    "        current_loss = 0\n",
    "        current_corrects = 0\n",
    "        model\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    #train step\n",
    "    for batch_idx, (images, labels) in enumerate(\n",
    "         tqdm(train_dataloader, position=0, leave=True, desc = 'train')\n",
    "    ):\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        #get predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # print(outputs)\n",
    "        # print(preds)\n",
    "        \n",
    "        #get loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "\n",
    "        ###### 여기까지가 forward ###\n",
    "\n",
    "        #Backpropagation\n",
    "\n",
    "        #optimitizer 초기화(zero화)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #perfrom optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss +=loss.item()\n",
    "        current_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if train_step % log_interval == 0:\n",
    "            train_loss = current_loss / log_interval\n",
    "            train_acc = current_corrects/log_interval\n",
    "            print(\n",
    "                f\"{train_step}: train_loss: {train_loss}, train_acc: {train_acc}\" \n",
    "            )\n",
    "            writer.add_scalar(\"Loss/train\", train_step)\n",
    "            writer.add_scalar(\"Acc/train\", train_step)\n",
    "            writer.add_images(\"Images/train\", images, train_step)\n",
    "            writer.add_graph(model, images)\n",
    "            current_loss = 0\n",
    "            current_corrects = 0\n",
    "\n",
    "        train_step += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# os.makedirs(\"./logs/models\", exist_ok=True)\n",
    "# torch.save(model, os.path.join(log_model_path, \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs/2022-04-28 15:31:53.026827-MLPWithDropout/models'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPWithDropout(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = torch.load(os.path.join(log_model_path, \"val_loss-0.03366972133517265-model.ckpt\"))\n",
    "loaded_model.eval()\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"numpy softmax\"\n",
    "    max = np.max(x, axis=axis, keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x, axis = axis, keepdims=True)\n",
    "    f_x = e_x / sum\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 100/100 [00:01<00:00, 71.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "test_labels_list = []\n",
    "test_preds_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "\n",
    "for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position=0, leave=True, desc=\"testing\")):\n",
    "    #forward\n",
    "    test_outputs = loaded_model(test_images)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    final_outs = softmax(test_outputs.detach().numpy(), axis=1)\n",
    "    test_outputs_list.extend(final_outs)\n",
    "    test_preds_list.extend(test_preds.detach().numpy())\n",
    "    test_labels_list.extend(test_preds.detach().numpy())\n",
    "\n",
    "test_preds_list = np.array(test_preds_list)\n",
    "test_labels_list = np.array(test_labels_list)\n",
    "\n",
    "print(f\"acc: {np.mean(test_preds_list==test_labels_list)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993464765376935\n"
     ]
    }
   ],
   "source": [
    "#ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr={}\n",
    "tpr={}\n",
    "thresh={}\n",
    "n_class = 10\n",
    "\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:,i], pos_label=i)\n",
    "\n",
    "#print(fpr)\n",
    "\n",
    "#plot\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], linestyle = '--', label=f\"class{i} vs Rest\")\n",
    "plt.title(\"Multi-class ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(test_labels_list, test_outputs_list, multi_class='ovo', average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7244abc13d988a7e7d2c4c53272249ae82a63923609912adda01122398923101"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
